#!/bin/bash
echo "//this code is generated by gen_tensor_blas.sh
#pragma once
#include \"../common/monolish_common.hpp\"

namespace monolish {
/**
* @brief
* Basic Linear Algebra Subprograms for Dense Tensor, Dense Matrix, Sparse Matrix, Vector and
* Scalar
*/
namespace blas {
"

echo "
/**
 * @addtogroup BLASLV3
 * @{
 */
"

## copy tensor_Dense
echo "
/**
 * \defgroup tens_copy_Dense monolish::blas::copy (tensor_Dense)
 * @brief Dense tensor copy (C=A)
 * @{
 */
 /**
 * @brief Dense tensor copy (C=A)
 * @param A monolish Dense tensor (size M x N)
 * @param C monolish Dense tensor (size M x N)
 * @note
 * - # of computation: M x N
 * - Multi-threading: true
 * - GPU acceleration: true
 *    - # of data transfer: 0
 */ "
for prec in double float; do
  echo "void copy(const tensor::tensor_Dense<$prec> &A, tensor::tensor_Dense<$prec> &C);"
done

echo "/**@}*/"

##############################################

#tscal tensor_Dense
echo "
/**
 * \defgroup tscal_dense monolish::blas::tscal (tensor_Dense)
 * @brief Dense tensor scal: A = alpha * A
 * @{
 */
/**
 * @brief Dense tensor scal: A = alpha * A
 * @param alpha scalar value
 * @param A Dense tensor (size M x N)
 * @note
 * - # of computation: MN
 * - Multi-threading: true
 * - GPU acceleration: true
 *    - # of data transfer: 0
*/ "
for prec in double float; do
  echo "void tscal(const $prec alpha, tensor::tensor_Dense<$prec> &A);"
done

echo "/**@}*/"

##############################################
# times scalar (almost same as tscal)

# times scalar tensor_Dense
echo "
/**
 * \defgroup times monolish::blas::times
 * @brief element by element multiplication
 * @{
 */
/**
 * @brief Dense tensor times: C = alpha * A
 * @param alpha scalar value
 * @param A Dense tensor (size M x N)
 * @param C Dense tensor (size M x N)
 * @note
 * - # of computation: MN
 * - Multi-threading: true
 * - GPU acceleration: true
 *    - # of data transfer: 0
*/ "
for prec in double float; do
  echo "void times(const $prec alpha, const tensor::tensor_Dense<$prec> &A, tensor::tensor_Dense<$prec> &C);"
done
echo "/**@}*/"

##############################################

#tensadd tensor_Dense
echo "
/**
 * \defgroup madd_dense monolish::blas::tensadd (tensor_Dense)
 * @brief Dense tensor addition: C = A + B
 * @{
 */
/**
 * @brief Dense tensor addition: C = A + B
 * @param A Dense tensor (size M x N)
 * @param B Dense tensor (size M x N)
 * @param C Dense tensor (size M x N)
 * @note
 * - # of computation: MN
 * - Multi-threading: true
 * - GPU acceleration: true
 *    - # of data transfer: 0
*/ "
for prec in double float; do
  echo "void tensadd(const tensor::tensor_Dense<$prec> &A, const tensor::tensor_Dense<$prec> &B, tensor::tensor_Dense<$prec> &C);"
done
echo "/**@}*/"

echo ""

#tenssub tensor_Dense
echo "
/**
 * \defgroup msub_dense monolish::blas::tenssub (tensor_Dense)
 * @brief Dense tensor subtract: C = A - B
 * @{
 */
/**
 * @brief Dense tensor subtract: C = A - B
 * @param A Dense tensor (size M x N)
 * @param B Dense tensor (size M x N)
 * @param C Dense tensor (size M x N)
 * @note
 * - # of computation: MN
 * - Multi-threading: true
 * - GPU acceleration: true
 *    - # of data transfer: 0
*/ "
for prec in double float; do
  echo "void tenssub(const tensor::tensor_Dense<$prec> &A, const tensor::tensor_Dense<$prec> &B, tensor::tensor_Dense<$prec> &C);"
done
echo "/**@}*/"

echo ""
#################################

#tensmul tensor_Dense
echo "
/**
 * \defgroup mm_dense monolish::blas::tensmul (tensor_Dense, tensor_Dense, tensor_Dense)
 * @brief Dense tensor multiplication: C = AB
 * @{
 */
/**
 * @brief Dense tensor multiplication: C = AB
 * @param A Dense tensor (size M x K)
 * @param B Dense tensor (size K x N)
 * @param C Dense tensor (size M x N)
 * @note
 * - # of computation: 2MNK
 * - Multi-threading: true
 * - GPU acceleration: true
 *    - # of data transfer: 0
*/ "
for prec in double float; do
  echo "void tensmul(const tensor::tensor_Dense<$prec> &A, const tensor::tensor_Dense<$prec> &B, tensor::tensor_Dense<$prec> &C);"
done
echo "/**@}*/"

echo "
/**
 * \defgroup mm_dense monolish::blas::tensmul (Float, tensor_Dense, tensor_Dense, Float, tensor_Dense)
 * @brief Dense tensor multiplication: C = aAB+bC
 * @{
 */
/**
 * @brief Dense tensor multiplication: C = aAB+bC
 * @param a Float
 * @param A Dense tensor (size M x K)
 * @param B Dense tensor (size K x N)
 * @param b Float
 * @param C Dense tensor (size M x N)
 * @note
 * - # of computation: 2MNK
 * - Multi-threading: true
 * - GPU acceleration: true
 *    - # of data transfer: 0
*/ "
for prec in double float; do
  echo "void tensmul(const $prec &a, const tensor::tensor_Dense<$prec> &A, const tensor::tensor_Dense<$prec> &B, const $prec &b, tensor::tensor_Dense<$prec> &C);"
done
echo "/**@}*/"

#tensmul_* tensor_Dense
# for TA in N T; do
# for TB in N T; do
# echo "
# /**
#  * \defgroup mm_dense_$TA$TB monolish::blas::tensmul_$TA$TB (tensor_Dense, tensor_Dense, tensor_Dense)
#  * @brief Dense tensor multiplication: C = A^$TA B^$TB
#  * @{
#  */
# /**
#  * @brief Dense tensor multiplication: C = A^$TA B^$TB
#  * @param A Dense tensor (size M x K)
#  * @param B Dense tensor (size K x N)
#  * @param C Dense tensor (size M x N)
#  * @note
#  * - # of computation: 2MNK
#  * - Multi-threading: true
#  * - GPU acceleration: true
#  *    - # of data transfer: 0
# */ "
# for prec in double float; do
#   echo "void tensmul_$TA$TB(const tensor::tensor_Dense<$prec> &A, const tensor::tensor_Dense<$prec> &B, tensor::tensor_Dense<$prec> &C);"
# done
# echo "/**@}*/"
# done
# done

echo "}"
echo "}"
