// this code is generated by gen_tensor_blas.sh
#pragma once
#include "../common/monolish_common.hpp"

namespace monolish {
/**
 * @brief
 * Basic Linear Algebra Subprograms for Dense Matrix, Sparse Matrix, Vector and
 * Scalar
 */
namespace blas {

/**
 * @addtogroup BLASLV3
 * @{
 */

/**
 * \defgroup tens_copy_Dense monolish::blas::copy (tensor_Dense)
 * @brief tensor_Dense tensor copy (C=A)
 * @{
 */
/**
 * @brief tensor_Dense tensor copy (C=A)
 * @param A monolish tensor_Dense tensor
 * @param C monolish tensor_Dense tensor
 * @note
 * - # of computation: size
 * - Multi-threading: true
 * - GPU acceleration: true
 *    - # of data transfer: 0
 */
void copy(const tensor::tensor_Dense<double> &A,
          tensor::tensor_Dense<double> &C);
void copy(const tensor::tensor_Dense<float> &A, tensor::tensor_Dense<float> &C);
/**@}*/

/**
 * \defgroup tscal_dense monolish::blas::tscal (tensor_Dense)
 * @brief tensor_Dense tensor scal: A = alpha * A
 * @{
 */
/**
 * @brief tensor_Dense tensor scal: A = alpha * A
 * @param alpha scalar value
 * @param A Dense tensor
 * @note
 * - # of computation: size
 * - Multi-threading: true
 * - GPU acceleration: true
 *    - # of data transfer: 0
 */
void tscal(const double alpha, tensor::tensor_Dense<double> &A);
void tscal(const float alpha, tensor::tensor_Dense<float> &A);
/**@}*/

/**
 * \defgroup times monolish::blas::times
 * @brief element by element multiplication
 * @{
 */
/**
 * @brief tensor_Dense tensor times: C = alpha * A
 * @param alpha scalar value
 * @param A tensor_Dense tensor
 * @param C tensor_Dense tensor
 * @note
 * - # of computation: size
 * - Multi-threading: true
 * - GPU acceleration: true
 *    - # of data transfer: 0
 */
void times(const double alpha, const tensor::tensor_Dense<double> &A,
           tensor::tensor_Dense<double> &C);
void times(const float alpha, const tensor::tensor_Dense<float> &A,
           tensor::tensor_Dense<float> &C);
/**@}*/

/**
 * \defgroup madd_dense monolish::blas::tensadd (tensor_Dense)
 * @brief tensor_Dense tensor addition: C = A + B
 * @{
 */
/**
 * @brief Dense tensor addition: C = A + B
 * @param A tensor_Dense tensor
 * @param B tensor_Dense tensor
 * @param C tensor_Dense tensor
 * @note
 * - # of computation: size
 * - Multi-threading: true
 * - GPU acceleration: true
 *    - # of data transfer: 0
 */
void tensadd(const tensor::tensor_Dense<double> &A,
             const tensor::tensor_Dense<double> &B,
             tensor::tensor_Dense<double> &C);
void tensadd(const tensor::tensor_Dense<float> &A,
             const tensor::tensor_Dense<float> &B,
             tensor::tensor_Dense<float> &C);
/**@}*/

/**
 * \defgroup msub_dense monolish::blas::tenssub (tensor_Dense)
 * @brief tensor_Dense tensor subtract: C = A - B
 * @{
 */
/**
 * @brief Dense tensor subtract: C = A - B
 * @param A tensor_Dense tensor
 * @param B tensor_Dense tensor
 * @param C tensor_Dense tensor
 * @note
 * - # of computation: ?
 * - Multi-threading: true
 * - GPU acceleration: true
 *    - # of data transfer: 0
 */
void tenssub(const tensor::tensor_Dense<double> &A,
             const tensor::tensor_Dense<double> &B,
             tensor::tensor_Dense<double> &C);
void tenssub(const tensor::tensor_Dense<float> &A,
             const tensor::tensor_Dense<float> &B,
             tensor::tensor_Dense<float> &C);
/**@}*/

/**
 * \defgroup mm_dense monolish::blas::tensmul (tensor_Dense, tensor_Dense,
 * tensor_Dense)
 * @brief tensor_Dense tensor multiplication: C = AB
 * @{
 */
/**
 * @brief tensor_Dense tensor multiplication: C = AB
 * @param A tensor_Dense tensor
 * @param B tensor_Dense tensor
 * @param C tensor_Dense tensor
 * @note
 * - # of computation: ?
 * - Multi-threading: true
 * - GPU acceleration: true
 *    - # of data transfer: 0
 */
void tensmul(const tensor::tensor_Dense<double> &A,
             const tensor::tensor_Dense<double> &B,
             tensor::tensor_Dense<double> &C);
void tensmul(const tensor::tensor_Dense<float> &A,
             const tensor::tensor_Dense<float> &B,
             tensor::tensor_Dense<float> &C);
/**@}*/

/**
 * \defgroup mm_dense monolish::blas::tensmul (Float, tensor_Dense,
 * tensor_Dense, Float, tensor_Dense)
 * @brief tensor_Dense tensor multiplication: C = aAB+bC
 * @{
 */
/**
 * @brief tensor_Dense tensor multiplication: C = aAB+bC
 * @param a Float
 * @param A tensor_Dense tensor
 * @param B tensor_Dense tensor
 * @param b Float
 * @param C tensor_Dense tensor
 * @note
 * - # of computation: ?
 * - Multi-threading: true
 * - GPU acceleration: true
 *    - # of data transfer: 0
 */
void tensmul(const double &a, const tensor::tensor_Dense<double> &A,
             const tensor::tensor_Dense<double> &B, const double &b,
             tensor::tensor_Dense<double> &C);
void tensmul(const float &a, const tensor::tensor_Dense<float> &A,
             const tensor::tensor_Dense<float> &B, const float &b,
             tensor::tensor_Dense<float> &C);
/**@}*/
} // namespace blas
} // namespace monolish
